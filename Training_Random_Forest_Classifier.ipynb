{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Random_Forest_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWziu9Zxkt1f"
      },
      "source": [
        "import os\n",
        "import json \n",
        "img_list = os.listdir('path_to_images')\n",
        "import torch\n",
        "torch.save(img_list, 'path_to_save_image_list')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Il3Qt4L0XG"
      },
      "source": [
        "with open('path_to_image_captions_in_test_set_jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "for json_str in json_list:\n",
        "    result = json.loads(json_str)\n",
        "    dev.append(result)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dkONl9rMeUw"
      },
      "source": [
        "train = []\n",
        "with open('path_to_image_captions_in_train_set_jsonl', 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "\n",
        "for json_str in json_list:\n",
        "    result = json.loads(json_str)\n",
        "    train.append(result)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0bQkxiFOUxb"
      },
      "source": [
        "##Training Without Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8dSbndaK1Uy"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train)\n",
        "train_df.reset_index(drop=True, inplace=False)\n",
        "train_df = train_df.sort_values(by=['id'])\n",
        "train_df = train_df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzPHlOnGxWv_"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def oscar_outputs_to_xgbdims(oscar_output_path):\n",
        "  oscar_output = torch.load(oscar_output_path)\n",
        "  vec1_list = []\n",
        "  vec2_list = []\n",
        "  label_list = []\n",
        "  for entry_ids in list(oscar_output.keys()):\n",
        "    oscar_entry = oscar_output[entry_ids]\n",
        "    vec1 = oscar_entry['vector1']\n",
        "    vec2 = oscar_entry['vector2'].squeeze(0)\n",
        "    label = torch.tensor(oscar_entry['hateful']).unsqueeze(0)\n",
        "    vec1_list.append(vec1)\n",
        "    vec2_list.append(vec2)\n",
        "    label_list.append(label)\n",
        "\n",
        "  label_array = torch.cat(label_list)\n",
        "  data_array1 = torch.stack(vec1_list)\n",
        "  data_array2 = torch.stack(vec2_list)\n",
        "\n",
        "  return label_array, data_array1, data_array2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ueCrWXBOli"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "label = []\n",
        "data1 = []\n",
        "data2 = []\n",
        "\n",
        "greater_dir_path = 'path_to_train_oscar_tensors'\n",
        "\n",
        "for output_name in os.listdir(greater_dir_path):\n",
        "  output_path = os.path.join(greater_dir_path, output_name)\n",
        "  l, d1, d2 = oscar_outputs_to_xgbdims(output_path)\n",
        "  label.append(l)\n",
        "  data1.append(d1)\n",
        "  data2.append(d2)\n",
        "\n",
        "label = torch.cat(label)\n",
        "data1 = torch.vstack(data1)\n",
        "data2 = torch.vstack(data2)\n",
        "\n",
        "label = label.detach().numpy()\n",
        "data1 = data1.detach().numpy()\n",
        "data2 = data2.detach().numpy()\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "# data1, label, test_size=0.2, random_state=42)\n",
        "# dtrain1 = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "# params = {\n",
        "#   'colsample_bynode': 0.8,\n",
        "#   'learning_rate': 1,\n",
        "#   'max_depth': 5,\n",
        "#   'num_parallel_tree': 50,\n",
        "#   'objective': 'binary:logistic',\n",
        "#   'subsample': 0.8,\n",
        "# }\n",
        "\n",
        "# params['gpu_id'] = 0\n",
        "# params['tree_method'] = 'gpu_hist'\n",
        "\n",
        "# bst = xgb.train(params, dtrain1, num_boost_round=10)\n",
        "\n",
        "# y_pred = bst.predict(xgb.DMatrix(X_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-6DG0wPCG-M"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "data2, label, test_size=0.3, random_state=42)\n",
        "dtrain1 = xgb.DMatrix(X_train, label=y_train)\n",
        "\n",
        "params = {\n",
        "  'colsample_bynode': 0.8,\n",
        "  'learning_rate': 1,\n",
        "  'max_depth': 10,\n",
        "  'num_parallel_tree': 10,\n",
        "  'objective': 'binary:logistic',\n",
        "  'subsample': 0.8,\n",
        "}\n",
        "\n",
        "params['gpu_id'] = 0\n",
        "params['tree_method'] = 'gpu_hist'\n",
        "\n",
        "bst = xgb.train(params, dtrain1, num_boost_round=10)\n",
        "\n",
        "y_pred = bst.predict(xgb.DMatrix(X_test))\n",
        "\n",
        "y_pred = np.array([1 if y_pred[i] >= 0.5 else 0 for i in range(0, y_pred.shape[0])])\n",
        "print('acc: '+str(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "\n",
        "print(f1_score(y_test, y_pred, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gxTN5tJW1ld"
      },
      "source": [
        "print(f1_score(y_test, y_pred, average='micro'))\n",
        "\n",
        "print(f1_score(y_test, y_pred, average='macro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lbVZrZBCaEi"
      },
      "source": [
        "import xgboost as xgb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O22Vq0QDFpFW"
      },
      "source": [
        "bst.predict(xgb.DMatrix(data1[3][np.newaxis, :])).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApgNIIQUQEto"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "greater_dir_path = 'path_to_test_oscar_tensors'\n",
        "\n",
        "dev_label = []\n",
        "dev_data1 = []\n",
        "dev_data2 = []\n",
        "\n",
        "for output_name in os.listdir(greater_dir_path):\n",
        "  output_path = os.path.join(greater_dir_path, output_name)\n",
        "  l, d1, d2 = oscar_outputs_to_xgbdims(output_path)\n",
        "  dev_label.append(l)\n",
        "  dev_data1.append(d1)\n",
        "  dev_data2.append(d2)\n",
        "\n",
        "dev_label = torch.cat(dev_label)\n",
        "dev_data1 = torch.vstack(dev_data1)\n",
        "dev_data2 = torch.vstack(dev_data2)\n",
        "\n",
        "dev_label = dev_label.detach().numpy()\n",
        "dev_data1 = dev_data1.detach().numpy()\n",
        "dev_data2 = dev_data2.detach().numpy()\n",
        "\n",
        "dev_dtrain1 = xgb.DMatrix(dev_data1)\n",
        "\n",
        "dev_pred = bst.predict(dev_dtrain1)\n",
        "dev_pred = np.array([1 if dev_pred[i] >= 0.7 else 0 for i in range(0, dev_pred.shape[0])])\n",
        "\n",
        "accuracy_score(dev_pred, dev_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}