{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Prepare_VinVl_Tensors_for_OSCAR_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TS-OxcpT9s-"
      },
      "source": [
        "##Stage 0: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wN_byIjbaJE"
      },
      "source": [
        "!pip install ipython h5py nltk joblib jupyter pandas scipy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7OttHG2Pkxq"
      },
      "source": [
        "!pip install ninja yacs>=0.1.8 cython matplotlib tqdm opencv-python numpy>=1.19.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfmVXE3lPuoa"
      },
      "source": [
        "!pip install timm einops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-d2WgO4TPkP"
      },
      "source": [
        "!pip install cityscapesscripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZk4QhEWT5EH"
      },
      "source": [
        "!pip install pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ubLydheFiqd"
      },
      "source": [
        "!pip install yamlloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Z0hOBrP-jh"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU7O-w11QEG2"
      },
      "source": [
        "#!git clone https://github.com/microsoft/scene_graph_benchmark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3lS1dhGQIfB"
      },
      "source": [
        "%cd scene_graph_benchmark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZUi9IR_QOtr"
      },
      "source": [
        "!python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_V58C7xLVhh"
      },
      "source": [
        "##Extract Features Using VinVl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCbvyieuksLR"
      },
      "source": [
        "##Modify the /content/drive/MyDrive/scene_graph_benchmark/sgg_configs/vgattr/vinvl_x152c4.yaml file before running VinVl\n",
        "\n",
        "There are four entries to be changed: \n",
        "\n",
        "1. **DATASET.TEST**: this is an entry of the yaml file denoting the paths of the tsv files for VinVl input. This yaml file should be stored in the data directory (which corresponds to **DATA_DIR**). This yaml file is used to build up ***VGTSVDataset*** (scene_graph_benchmark/maskrcnn_benchmark/data/datasets/vg_tsv.py) \n",
        "for dataloader.                                                         Only images tsv file need to be present in this yaml files, as other three tsv files, label_file, hw_file, linelist_file, are optinal for building the super ***TSVDataset*** (scene_graph_benchmark/maskrcnn_benchmark/data/datasets/tsv_dataset.py).                                                                       This is indicated by line 5 of the ***config_tsv_dataset_args*** in scene_graph_benchmark/maskrcnn_benchmark/data/datasets/utils/config_args.py; line 30, 40, 42, and 170 in scene_graph_benchmark/maskrcnn_benchmark/data/build.py; line 55 of scene_graph_benchmark/tools/test_sg_net.py.\n",
        "\n",
        "2. **DATA_DIR**: this is an entry of the yaml file denoting the directory that stores tsv yaml files, as indicated by line 5 of maskrcnn_benchmark/data/datasets/utils/config_args.py. \n",
        "\n",
        "3. **DATASETS.LABELMAP_FILE**: this is the entry that contains the full path of the label map json file, as indicated by line 56 of scene_graph_benchmark/tools/test_sg_net.py and line 30 of maskrcnn_benchmark/data/datasets/utils/load_files.py.\n",
        "\n",
        "4. **OUTPUT_DIR**: this is the entry that denotes the directory where the result of VinVl inference will be stored.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVpUHI0yLGJr"
      },
      "source": [
        "##Fetch Image Files according to Image Names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsZLRiyEXvw2"
      },
      "source": [
        "# visualize VinVL object detection\n",
        "# pretrained models at https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/vinvl_vg_x152c4.pth\n",
        "# the associated labelmap at https://penzhanwu2.blob.core.windows.net/sgg/sgg_benchmark/vinvl_model_zoo/VG-SGG-dicts-vgoi6-clipped.json\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import os.path as op\n",
        "import argparse\n",
        "import json\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from scene_graph_benchmark.scene_parser import SceneParser\n",
        "from scene_graph_benchmark.AttrRCNN import AttrRCNN\n",
        "from maskrcnn_benchmark.data.transforms import build_transforms\n",
        "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
        "from maskrcnn_benchmark.config import cfg\n",
        "from scene_graph_benchmark.config import sg_cfg\n",
        "from maskrcnn_benchmark.data.datasets.utils.load_files import \\\n",
        "    config_dataset_file\n",
        "from maskrcnn_benchmark.data.datasets.utils.load_files import load_labelmap_file\n",
        "from maskrcnn_benchmark.utils.miscellaneous import mkdir\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eT0hOdk9lDQ"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def cv2Img_to_Image(input_img):\n",
        "    cv2_img = input_img.copy()\n",
        "    img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n",
        "    img = Image.fromarray(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "def detect_objects_on_single_image(model, transforms, cv2_img):\n",
        "    # cv2_img is the original input, so we can get the height and \n",
        "    # width information to scale the output boxes.\n",
        "    img_input = cv2Img_to_Image(cv2_img)\n",
        "    img_input, _ = transforms(img_input, target=None)\n",
        "    img_input = img_input.to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = model(img_input)[0].to('cpu')\n",
        "    #     prediction = prediction[0].to(torch.device(\"cpu\"))\n",
        "\n",
        "    img_height = cv2_img.shape[0]\n",
        "    img_width = cv2_img.shape[1]\n",
        "\n",
        "    prediction = prediction.resize((img_width, img_height))\n",
        "    \n",
        "    return prediction\n",
        "\n",
        "#Setting configuration\n",
        "cfg.set_new_allowed(True)\n",
        "cfg.merge_from_other_cfg(sg_cfg)\n",
        "cfg.set_new_allowed(False)\n",
        "#Configuring VinVl\n",
        "cfg.merge_from_file('path_to_vinvl_x152c4.yaml')\n",
        "\n",
        "#This is a list specifying the values for additional arguments, it encompasses pairs of list and values in an ordered manner\n",
        "#MODEL.WEIGHT specifies the full path of the VinVl weight pth file\n",
        "#DATA_DIR specifies the directory that contains VinVl input tsv configuration yaml file\n",
        "argument_list = [\n",
        "                 'MODEL.WEIGHT', 'path_to_vg_x152c4.pth',\n",
        "                 'MODEL.ROI_HEADS.NMS_FILTER', 1,\n",
        "                 'MODEL.ROI_HEADS.SCORE_THRESH', 0.2, \n",
        "                 'DATA_DIR', \"\",\n",
        "                 'TEST.IGNORE_BOX_REGRESSION', False,\n",
        "                 'MODEL.ATTRIBUTE_ON', True\n",
        "                 ]\n",
        "cfg.merge_from_list(argument_list)\n",
        "cfg.freeze()\n",
        "\n",
        "#     assert op.isfile(args.img_file), \\\n",
        "#         \"Image: {} does not exist\".format(args.img_file)\n",
        "\n",
        "output_dir = cfg.OUTPUT_DIR\n",
        "#     mkdir(output_dir)\n",
        "\n",
        "\n",
        "model = AttrRCNN(cfg)\n",
        "model.to(cfg.MODEL.DEVICE)\n",
        "model.eval()\n",
        "\n",
        "checkpointer = DetectronCheckpointer(cfg, model, save_dir=output_dir)\n",
        "checkpointer.load(cfg.MODEL.WEIGHT)\n",
        "\n",
        "# dataset labelmap is used to convert the prediction to class labels\n",
        "# dataset_labelmap_file = config_dataset_file(cfg.DATA_DIR, cfg.DATASETS.LABELMAP_FILE)\n",
        "#     assert dataset_labelmap_file\n",
        "#path to input labelmap file\n",
        "# labelmap_file = 'path_to_vinvl_labelmap.json'\n",
        "\n",
        "# dataset_allmap = json.load(open(labelmap_file, 'r'))\n",
        "# dataset_labelmap = {int(val): key for key, val in dataset_allmap['label_to_idx'].items()}\n",
        "\n",
        "transforms = build_transforms(cfg, is_train=False)\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_YArcqKX9M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvR8zY2_Duy"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import torch\n",
        "\n",
        "dets = {}\n",
        "greater_dataset_path = 'path_to_image_datasets'\n",
        "\n",
        "def save_vinvl_prediction(train_csv_dataset_path, i):\n",
        "# input_img_directory = 'path_to_images'\n",
        "#need to be pth\n",
        "  dets = {}\n",
        "\n",
        "  train_dataset = pd.read_csv(train_csv_dataset_path) \n",
        "\n",
        "  train_data_names = list(train_dataset['img'])\n",
        "  n = 0\n",
        "  for img_name in train_data_names:\n",
        "    if n%100 == 0:\n",
        "      print(n)\n",
        "\n",
        "    n=n+1\n",
        "\n",
        "    img_file_path = os.path.join(greater_dataset_path, img_name)\n",
        "\n",
        "    cv2_img = cv2.imread(img_file_path)\n",
        "\n",
        "    img_height = cv2_img.shape[0]\n",
        "    img_width = cv2_img.shape[1]\n",
        "\n",
        "    det = detect_objects_on_single_image(model, transforms, cv2_img)\n",
        "  \n",
        "#   prediction contains ['labels',\n",
        "#  'scores',\n",
        "#  'box_features',\n",
        "#  'scores_all',\n",
        "#  'boxes_all',\n",
        "#  'attr_labels',\n",
        "#  'attr_scores']\n",
        "# box_features are used for oscar\n",
        "\n",
        "\n",
        "    det_dict ={key : det.get_field(key) for key in det.fields()}\n",
        "    boxes = det.get_field('boxes_all')[:, 0,:]\n",
        "    box_width = boxes[:, 2] - boxes[:, 0]\n",
        "    box_height = boxes[:, 3] - boxes[:, 1]\n",
        "\n",
        "\n",
        "    scaled_width = box_width / img_width\n",
        "    scaled_height = box_height / img_height\n",
        "\n",
        "    scaled_width = scaled_width[..., np.newaxis]\n",
        "    scaled_height = scaled_height[..., np.newaxis]\n",
        "\n",
        "    scaled_x = boxes[:, 0] / img_width\n",
        "    scaled_y = boxes[:, 1] / img_width\n",
        "\n",
        "    scaled_x = scaled_x[..., np.newaxis]\n",
        "    scaled_y = scaled_y[..., np.newaxis]\n",
        "\n",
        "    spatial_features = np.concatenate( (scaled_x, scaled_y, scaled_x + scaled_width, scaled_y + scaled_height, scaled_width, scaled_height), axis=1)\n",
        "    det_dict['spatial_features'] = torch.tensor(spatial_features)\n",
        "  \n",
        "\n",
        "\n",
        "    dets[os.path.basename(img_name).split('.')[0]] = det_dict\n",
        "\n",
        "    output_prediction_file_path = 'path_to_vinvl_output_'+str(i)+'.pth'\n",
        "  torch.save(dets, output_prediction_file_path)\n",
        "  \n",
        "for i in range(0,5):\n",
        "  save_vinvl_prediction('train_df'+str(i)+\".csv\", i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zfGcE3sx28f"
      },
      "source": [
        "import json\n",
        "labelmap_file = 'path_to_vinvl_labelmap.json'\n",
        "\n",
        "dataset_allmap = json.load(open(labelmap_file, 'r'))\n",
        "dataset_labelmap = {int(val): key for key, val in dataset_allmap['label_to_idx'].items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63_9Pjt1Rey"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "def append_hateful(vinvl_output_path, train_df_path):\n",
        "  vinvl_output_dict = torch.load(vinvl_output_path)\n",
        "  train_df = pd.read_csv(train_df_path)\n",
        "  dict_ids = list(vinvl_output_dict.keys())\n",
        "  n = 0\n",
        "  for id in dict_ids:\n",
        "    if n%100==0:\n",
        "      print(n)\n",
        "    n+=1\n",
        "    hateful = train_df.loc[train_df['id']==int(id)]['label'].values[0]\n",
        "    vinvl_output_dict[id]['hateful'] = hateful\n",
        "  torch.save(vinvl_output_dict, vinvl_output_path)\n",
        "\n",
        "for i in range(0, 6):\n",
        "  vinvl_output_path = 'path_to_vinvl_output_'+str(i)+'.pth'\n",
        "  train_df_path = 'path_to_train_df_'+str(i)+'.csv'\n",
        "  print(vinvl_output_path)\n",
        "  print(train_df_path)\n",
        "  append_hateful(vinvl_output_path, train_df_path)\n",
        "  print(\"*****************************************\")\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nZ3XPCS_NDa"
      },
      "source": [
        "import torch\n",
        "def clean_vinvl_output(vinvl_output_path):\n",
        "  vinvl_output = torch.load(vinvl_output_path)\n",
        "  dict_ids = list(vinvl_output.keys())\n",
        "  n = 0\n",
        "  for id in dict_ids:\n",
        "    if n%100==0:\n",
        "      print(n)\n",
        "    n += 1\n",
        "    new_entry = {}\n",
        "    old_entry = vinvl_output[id]\n",
        "    new_entry['labels'] = old_entry['labels']\n",
        "    new_entry['box_features'] = old_entry['box_features']\n",
        "    new_entry['caption'] = old_entry['caption']\n",
        "    new_entry['hateful'] = old_entry['hateful']\n",
        "    new_entry['spatial_features'] = old_entry['spatial_features']\n",
        "    vinvl_output[id] = new_entry\n",
        "  torch.save(vinvl_output, vinvl_output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylixItsHCAl-"
      },
      "source": [
        "for i in range(0, 6):\n",
        "  vinvl_output_path = 'path_to_vinvl_output_'+str(i)+'.pth'\n",
        "  print('********************************')\n",
        "  print(vinvl_output_path)\n",
        "  clean_vinvl_output(vinvl_output_path)\n",
        "  print()\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-BLH3lF8W2M",
        "outputId": "b81a529a-bf3d-42db-ed03-b710e6afc28e"
      },
      "source": [
        "%cd path_to_image_datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hateful_messages_dataset/image_datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_6woD2B-e7j"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "import torch\n",
        "import json\n",
        "\n",
        "dets = {}\n",
        "greater_dataset_path = ''\n",
        "jsonl_file_path = ''\n",
        "greater_output_directory = ''\n",
        "def vinvl_output_from_jsonl(jsonl_file_path, greater_dataset_path, greater_output_directory):\n",
        "\n",
        "  with open(jsonl_file_path, 'r') as json_file:\n",
        "    json_list = list(json_file)\n",
        "  n = 0\n",
        "  dets = {}\n",
        "  for json_str in json_list:\n",
        "    json_dict = json.loads(json_str)\n",
        "    img_caption = json_dict['text']\n",
        "    img_hateful = json_dict['label']\n",
        "    img_name = os.path.basename(json_dict['img'])\n",
        "    if n%100 == 0:\n",
        "      print(n)\n",
        "    n += 1\n",
        "\n",
        "    img_file_path = os.path.join(greater_dataset_path, img_name)\n",
        "\n",
        "    cv2_img = cv2.imread(img_file_path)\n",
        "\n",
        "    img_height = cv2_img.shape[0]\n",
        "    img_width = cv2_img.shape[1]\n",
        "\n",
        "    det = detect_objects_on_single_image(model, transforms, cv2_img)\n",
        "  \n",
        "#   prediction contains ['labels',\n",
        "#  'scores',\n",
        "#  'box_features',\n",
        "#  'scores_all',\n",
        "#  'boxes_all',\n",
        "#  'attr_labels',\n",
        "#  'attr_scores']\n",
        "# box_features are used for oscar\n",
        "\n",
        "    necessary_fields = ['labels','box_features']\n",
        "    det_dict ={key : det.get_field(key) for key in necessary_fields}\n",
        "    boxes = det.get_field('boxes_all')[:, 0,:]\n",
        "    box_width = boxes[:, 2] - boxes[:, 0]\n",
        "    box_height = boxes[:, 3] - boxes[:, 1]\n",
        "\n",
        "\n",
        "    scaled_width = box_width / img_width\n",
        "    scaled_height = box_height / img_height\n",
        "\n",
        "    scaled_width = scaled_width[..., np.newaxis]\n",
        "    scaled_height = scaled_height[..., np.newaxis]\n",
        "\n",
        "    scaled_x = boxes[:, 0] / img_width\n",
        "    scaled_y = boxes[:, 1] / img_width\n",
        "\n",
        "    scaled_x = scaled_x[..., np.newaxis]\n",
        "    scaled_y = scaled_y[..., np.newaxis]\n",
        "\n",
        "    spatial_features = np.concatenate( (scaled_x, scaled_y, scaled_x + scaled_width, scaled_y + scaled_height, scaled_width, scaled_height), axis=1)\n",
        "    det_dict['spatial_features'] = torch.tensor(spatial_features)\n",
        "    det_dict['caption'] = img_caption\n",
        "    det_dict['hateful'] = img_hateful\n",
        "\n",
        "\n",
        "    dets[os.path.basename(img_name).split('.')[0]] = det_dict\n",
        "\n",
        "  output_prediction_file_path = os.path.join(greater_output_directory, 'path_to_test_vinvl_output.pth')\n",
        "  torch.save(dets, output_prediction_file_path)\n",
        "  \n",
        "vinvl_output_from_jsonl(jsonl_file_path, greater_dataset_path, greater_output_directory)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}